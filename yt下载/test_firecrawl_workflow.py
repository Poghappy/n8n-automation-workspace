#!/usr/bin/env python3
"""
Firecrawl N8Nå·¥ä½œæµç¨‹æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•Firecrawlä¸N8Né›†æˆçš„å·¥ä½œæµç¨‹ï¼Œ
éªŒè¯ç½‘é¡µæŠ“å–å’Œåª’ä½“èµ„æºæå–åŠŸèƒ½ã€‚
"""

import requests
import json
import time
from typing import Dict, List, Optional
from urllib.parse import urlparse
import argparse


class FirecrawlWorkflowTester:
    """Firecrawlå·¥ä½œæµç¨‹æµ‹è¯•å™¨"""
    
    def __init__(self, webhook_url: str):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            webhook_url: N8Nå·¥ä½œæµç¨‹çš„Webhook URL
        """
        self.webhook_url = webhook_url
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'FirecrawlWorkflowTester/1.0'
        })
    
    def test_single_url(self, url: str, timeout: int = 30) -> Dict:
        """
        æµ‹è¯•å•ä¸ªURLçš„æŠ“å–
        
        Args:
            url: è¦æµ‹è¯•çš„URL
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            æŠ“å–ç»“æœå­—å…¸
        """
        print(f"ğŸ” æµ‹è¯•URL: {url}")
        
        payload = {"url": url}
        
        try:
            start_time = time.time()
            response = self.session.post(
                self.webhook_url,
                json=payload,
                timeout=timeout
            )
            end_time = time.time()
            
            response.raise_for_status()
            result = response.json()
            
            # æ·»åŠ æµ‹è¯•å…ƒæ•°æ®
            result['test_metadata'] = {
                'request_time': end_time - start_time,
                'status_code': response.status_code,
                'response_size': len(response.content)
            }
            
            print(f"âœ… æŠ“å–æˆåŠŸ - è€—æ—¶: {result['test_metadata']['request_time']:.2f}ç§’")
            return result
            
        except requests.exceptions.Timeout:
            print(f"â° è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)")
            return {"error": "timeout", "url": url}
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
            return {"error": str(e), "url": url}
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return {"error": "json_decode_error", "url": url, "response_text": response.text[:500]}
    
    def test_multiple_urls(self, urls: List[str], delay: float = 1.0) -> List[Dict]:
        """
        æµ‹è¯•å¤šä¸ªURLçš„æŠ“å–
        
        Args:
            urls: URLåˆ—è¡¨
            delay: è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            æŠ“å–ç»“æœåˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(urls)} ä¸ªURL")
        results = []
        
        for i, url in enumerate(urls, 1):
            print(f"\n[{i}/{len(urls)}]", end=" ")
            result = self.test_single_url(url)
            results.append(result)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            if i < len(urls) and delay > 0:
                time.sleep(delay)
        
        return results
    
    def analyze_results(self, results: List[Dict]) -> Dict:
        """
        åˆ†ææµ‹è¯•ç»“æœ
        
        Args:
            results: æµ‹è¯•ç»“æœåˆ—è¡¨
            
        Returns:
            åˆ†ææŠ¥å‘Šå­—å…¸
        """
        total_count = len(results)
        success_count = sum(1 for r in results if 'error' not in r and r.get('success', False))
        error_count = total_count - success_count
        
        # ç»Ÿè®¡åª’ä½“èµ„æº
        total_images = sum(r.get('mediaCount', {}).get('images', 0) for r in results if 'error' not in r)
        total_videos = sum(r.get('mediaCount', {}).get('videos', 0) for r in results if 'error' not in r)
        total_audios = sum(r.get('mediaCount', {}).get('audios', 0) for r in results if 'error' not in r)
        total_downloads = sum(r.get('mediaCount', {}).get('downloads', 0) for r in results if 'error' not in r)
        
        # ç»Ÿè®¡å“åº”æ—¶é—´
        response_times = [r.get('test_metadata', {}).get('request_time', 0) for r in results if 'test_metadata' in r]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # ç»Ÿè®¡é”™è¯¯ç±»å‹
        error_types = {}
        for result in results:
            if 'error' in result:
                error_type = result['error']
                error_types[error_type] = error_types.get(error_type, 0) + 1
        
        analysis = {
            'summary': {
                'total_urls': total_count,
                'successful': success_count,
                'failed': error_count,
                'success_rate': (success_count / total_count * 100) if total_count > 0 else 0
            },
            'media_stats': {
                'total_images': total_images,
                'total_videos': total_videos,
                'total_audios': total_audios,
                'total_downloads': total_downloads,
                'avg_images_per_page': total_images / success_count if success_count > 0 else 0,
                'avg_videos_per_page': total_videos / success_count if success_count > 0 else 0
            },
            'performance': {
                'avg_response_time': avg_response_time,
                'min_response_time': min(response_times) if response_times else 0,
                'max_response_time': max(response_times) if response_times else 0
            },
            'errors': error_types
        }
        
        return analysis
    
    def print_analysis(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        summary = analysis['summary']
        print(f"æ€»URLæ•°é‡: {summary['total_urls']}")
        print(f"æˆåŠŸæŠ“å–: {summary['successful']}")
        print(f"å¤±è´¥æ•°é‡: {summary['failed']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        
        # åª’ä½“èµ„æºç»Ÿè®¡
        media = analysis['media_stats']
        print(f"\nğŸ“¸ åª’ä½“èµ„æºç»Ÿè®¡:")
        print(f"  å›¾ç‰‡æ€»æ•°: {media['total_images']} (å¹³å‡ {media['avg_images_per_page']:.1f}/é¡µ)")
        print(f"  è§†é¢‘æ€»æ•°: {media['total_videos']} (å¹³å‡ {media['avg_videos_per_page']:.1f}/é¡µ)")
        print(f"  éŸ³é¢‘æ€»æ•°: {media['total_audios']}")
        print(f"  ä¸‹è½½æ–‡ä»¶: {media['total_downloads']}")
        
        # æ€§èƒ½ç»Ÿè®¡
        perf = analysis['performance']
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {perf['avg_response_time']:.2f}ç§’")
        print(f"  æœ€å¿«å“åº”: {perf['min_response_time']:.2f}ç§’")
        print(f"  æœ€æ…¢å“åº”: {perf['max_response_time']:.2f}ç§’")
        
        # é”™è¯¯ç»Ÿè®¡
        if analysis['errors']:
            print(f"\nâŒ é”™è¯¯ç»Ÿè®¡:")
            for error_type, count in analysis['errors'].items():
                print(f"  {error_type}: {count}æ¬¡")
    
    def save_results(self, results: List[Dict], filename: str):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Firecrawl N8Nå·¥ä½œæµç¨‹æµ‹è¯•å™¨')
    parser.add_argument('webhook_url', help='N8Nå·¥ä½œæµç¨‹çš„Webhook URL')
    parser.add_argument('--url', help='å•ä¸ªæµ‹è¯•URL')
    parser.add_argument('--urls-file', help='åŒ…å«URLåˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--delay', type=float, default=1.0, help='æ‰¹é‡æµ‹è¯•æ—¶çš„è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--timeout', type=int, default=30, help='è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--output', help='ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # éªŒè¯webhook URL
    parsed_url = urlparse(args.webhook_url)
    if not parsed_url.scheme or not parsed_url.netloc:
        print("âŒ æ— æ•ˆçš„Webhook URL")
        return
    
    tester = FirecrawlWorkflowTester(args.webhook_url)
    
    # å‡†å¤‡æµ‹è¯•URLåˆ—è¡¨
    test_urls = []
    
    if args.url:
        test_urls.append(args.url)
    
    if args.urls_file:
        try:
            with open(args.urls_file, 'r', encoding='utf-8') as f:
                file_urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                test_urls.extend(file_urls)
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {args.urls_file}")
            return
    
    # å¦‚æœæ²¡æœ‰æä¾›URLï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•URL
    if not test_urls:
        test_urls = [
            'https://example.com',
            'https://httpbin.org/html',
            'https://www.wikipedia.org'
        ]
        print("â„¹ï¸  ä½¿ç”¨é»˜è®¤æµ‹è¯•URL")
    
    print(f"ğŸ¯ Webhook URL: {args.webhook_url}")
    print(f"ğŸ“‹ æµ‹è¯•URLæ•°é‡: {len(test_urls)}")
    
    # æ‰§è¡Œæµ‹è¯•
    if len(test_urls) == 1:
        results = [tester.test_single_url(test_urls[0], args.timeout)]
    else:
        results = tester.test_multiple_urls(test_urls, args.delay)
    
    # åˆ†æç»“æœ
    analysis = tester.analyze_results(results)
    tester.print_analysis(analysis)
    
    # ä¿å­˜ç»“æœ
    if args.output:
        tester.save_results(results, args.output)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœï¼ˆä»…åœ¨å•ä¸ªURLæµ‹è¯•æ—¶ï¼‰
    if len(test_urls) == 1 and 'error' not in results[0]:
        result = results[0]
        print(f"\nğŸ“„ é¡µé¢è¯¦æƒ…:")
        print(f"  æ ‡é¢˜: {result.get('title', 'N/A')}")
        print(f"  æè¿°: {result.get('description', 'N/A')[:100]}...")
        print(f"  å†…å®¹é•¿åº¦: {result.get('contentStats', {}).get('wordCount', 0)} è¯")
        
        media_links = result.get('mediaLinks', {})
        if media_links.get('images'):
            print(f"\nğŸ–¼ï¸  å›¾ç‰‡é“¾æ¥ ({len(media_links['images'])}ä¸ª):")
            for i, img in enumerate(media_links['images'][:5], 1):
                print(f"  {i}. {img}")
            if len(media_links['images']) > 5:
                print(f"  ... è¿˜æœ‰ {len(media_links['images']) - 5} ä¸ª")


if __name__ == '__main__':
    main()