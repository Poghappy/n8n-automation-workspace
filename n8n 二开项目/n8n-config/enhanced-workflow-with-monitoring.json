{
  "name": "ç«é¸Ÿé—¨æˆ·æ–°é—»é‡‡é›†å·¥ä½œæµ - å¢å¼ºç›‘æ§ç‰ˆ",
  "description": "é›†æˆäº†å…¨é¢æ—¥å¿—è®°å½•å’Œç›‘æ§ç³»ç»Ÿçš„æ–°é—»é‡‡é›†å·¥ä½œæµ",
  "version": "2.0.0",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "cronExpression",
              "expression": "0 */30 * * * *"
            }
          ]
        }
      },
      "id": "cron-trigger",
      "name": "å®šæ—¶è§¦å‘å™¨",
      "type": "n8n-nodes-base.cron",
      "typeVersion": 1,
      "position": [240, 300]
    },
    
    {
      "parameters": {
        "functionCode": "// å·¥ä½œæµåˆå§‹åŒ–å’Œç›‘æ§ç³»ç»Ÿå¯åŠ¨\nconst PerformanceMetricsCollector = require('./performance-metrics-collector.js');\nconst WorkflowExecutionReporter = require('./workflow-execution-reporter.js');\n\n// åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ\nconst metricsCollector = new PerformanceMetricsCollector({\n  enableSystemMetrics: true,\n  enableWorkflowMetrics: true,\n  enableApiMetrics: true,\n  collectionInterval: 30000\n});\n\nconst executionReporter = new WorkflowExecutionReporter({\n  enableFileStorage: true,\n  enablePeriodicReports: true,\n  includePerformanceAnalysis: true\n});\n\n// å·¥ä½œæµåŸºæœ¬ä¿¡æ¯\nconst workflowId = $execution.id;\nconst startTime = Date.now();\n\n// æ•°æ®æºé…ç½®\nconst rssSources = [\n  { name: 'The Neuron', url: 'https://www.theneuron.ai/feed', category: 'AIèµ„è®¯', categoryId: 1 },\n  { name: 'Futurepedia', url: 'https://www.futurepedia.io/rss', category: 'AIå·¥å…·', categoryId: 1 },\n  { name: 'Superhuman', url: 'https://blog.superhuman.com/feed/', category: 'ç§‘æŠ€èµ„è®¯', categoryId: 1 },\n  { name: 'The Rundown AI', url: 'https://www.therundown.ai/feed', category: 'AIèµ„è®¯', categoryId: 1 }\n];\n\nconst githubSources = [\n  { name: 'GitHub Trending', repo: 'trending', category: 'å¼€æºé¡¹ç›®', categoryId: 1 }\n];\n\n// å·¥ä½œæµçŠ¶æ€è·Ÿè¸ª\nconst workflowStatus = {\n  executionId: workflowId,\n  workflowId: $workflow.id,\n  workflowName: $workflow.name,\n  startTime: startTime,\n  startTimestamp: new Date().toISOString(),\n  phase: 'initialization',\n  totalSources: rssSources.length + githubSources.length,\n  expectedSteps: [\n    'initialization',\n    'data_collection',\n    'content_processing', \n    'notion_storage',\n    'ai_management',\n    'firebird_publish',\n    'completion',\n    'reporting'\n  ],\n  currentStep: 1,\n  totalSteps: 8,\n  \n  // ç›‘æ§ç³»ç»Ÿå¼•ç”¨\n  metricsCollector: metricsCollector,\n  executionReporter: executionReporter\n};\n\n// æ”¶é›†åˆå§‹ç³»ç»ŸæŒ‡æ ‡\nconst initialMetrics = metricsCollector.collectSystemMetrics();\nconst initialWorkflowMetrics = metricsCollector.collectWorkflowMetrics({\n  executionId: workflowId,\n  workflowId: $workflow.id,\n  workflowName: $workflow.name,\n  nodeId: $node.id,\n  nodeName: $node.name,\n  itemsProcessed: 0,\n  dataSize: 0\n});\n\n// è®°å½•å·¥ä½œæµå¯åŠ¨æ—¥å¿—\nconsole.log('ğŸš€ å·¥ä½œæµå¯åŠ¨ - ç›‘æ§ç³»ç»Ÿå·²æ¿€æ´»:', JSON.stringify({\n  executionId: workflowId,\n  workflowName: $workflow.name,\n  totalSources: workflowStatus.totalSources,\n  expectedDuration: '5-10åˆ†é’Ÿ',\n  startTime: workflowStatus.startTimestamp,\n  monitoringEnabled: true,\n  systemMetrics: {\n    memoryUsage: Math.round(initialMetrics.memory.heapUsagePercent) + '%',\n    processUptime: Math.round(initialMetrics.process.uptime) + 's'\n  }\n}));\n\nreturn { \n  json: { \n    rssSources, \n    githubSources, \n    workflowStatus,\n    initialMetrics,\n    timestamp: new Date().toISOString(),\n    \n    // æ—¥å¿—è®°å½•å…ƒæ•°æ®\n    logMetadata: {\n      phase: 'initialization',\n      step: 1,\n      totalSteps: 8,\n      executionId: workflowId\n    }\n  } \n};"
      },
      "id": "workflow-initialization",
      "name": "å·¥ä½œæµåˆå§‹åŒ–ä¸ç›‘æ§å¯åŠ¨",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,\n      "position": [460, 300]
    },
    
    {
      "parameters": {
        "functionCode": "// ç»Ÿä¸€æ—¥å¿—è®°å½•èŠ‚ç‚¹ - åŸºäºé…ç½®æ–‡ä»¶\nconst logLevel = process.env.WORKFLOW_LOG_LEVEL || 'info';\nconst enableStructuredLogging = process.env.ENABLE_STRUCTURED_LOGGING !== 'false';\n\n// æ—¥å¿—çº§åˆ«æ˜ å°„\nconst LOG_LEVELS = {\n  error: 0,\n  warn: 1,\n  info: 2,\n  debug: 3,\n  trace: 4\n};\n\nconst currentLogLevel = LOG_LEVELS[logLevel] || LOG_LEVELS.info;\n\n// æ—¥å¿—è®°å½•å‡½æ•°\nfunction log(level, category, message, metadata = {}) {\n  if (LOG_LEVELS[level] > currentLogLevel) {\n    return;\n  }\n  \n  const logEntry = {\n    timestamp: new Date().toISOString(),\n    level: level.toUpperCase(),\n    category: category,\n    executionId: $execution.id,\n    workflowId: $workflow.id,\n    workflowName: $workflow.name,\n    nodeId: $node.id || 'workflow-logger',\n    nodeName: $node.name || 'å·¥ä½œæµæ—¥å¿—è®°å½•å™¨',\n    message: message,\n    metadata: {\n      ...metadata,\n      memoryUsage: process.memoryUsage ? process.memoryUsage() : null,\n      timestamp: Date.now()\n    }\n  };\n  \n  // æ•æ„Ÿæ•°æ®è„±æ•\n  if (logEntry.metadata) {\n    logEntry.metadata = sanitizeMetadata(logEntry.metadata);\n  }\n  \n  if (enableStructuredLogging) {\n    console.log(JSON.stringify(logEntry));\n  } else {\n    console.log(`[${logEntry.timestamp}] ${logEntry.level} [${logEntry.category}] ${logEntry.message}`);\n  }\n  \n  return logEntry;\n}\n\n// æ•æ„Ÿæ•°æ®è„±æ•å‡½æ•°\nfunction sanitizeMetadata(metadata) {\n  const sensitiveKeys = ['password', 'token', 'key', 'secret', 'credential', 'auth'];\n  const sanitized = { ...metadata };\n  \n  function sanitizeObject(obj) {\n    if (typeof obj !== 'object' || obj === null) return obj;\n    \n    const result = Array.isArray(obj) ? [] : {};\n    \n    for (const [key, value] of Object.entries(obj)) {\n      const lowerKey = key.toLowerCase();\n      const isSensitive = sensitiveKeys.some(sensitive => lowerKey.includes(sensitive));\n      \n      if (isSensitive && typeof value === 'string') {\n        result[key] = '***MASKED***';\n      } else if (typeof value === 'object' && value !== null) {\n        result[key] = sanitizeObject(value);\n      } else if (typeof value === 'string' && value.length > 1000) {\n        result[key] = value.substring(0, 1000) + '...[truncated]';\n      } else {\n        result[key] = value;\n      }\n    }\n    \n    return result;\n  }\n  \n  return sanitizeObject(sanitized);\n}\n\n// è·å–è¾“å…¥æ•°æ®\nconst inputData = $input.first()?.json || {};\nconst logCategory = inputData.logMetadata?.category || 'workflow';\nconst logMessage = inputData.logMetadata?.message || 'å·¥ä½œæµæ­¥éª¤æ‰§è¡Œ';\nconst logMetadata = inputData.logMetadata || {};\nconst logLevelOverride = inputData.logMetadata?.level || 'info';\n\n// æ€§èƒ½æŒ‡æ ‡æ”¶é›†\nconst performanceMetrics = {\n  nodeExecutionTime: Date.now() - (inputData.workflowStatus?.startTime || Date.now()),\n  itemCount: $input.all().length,\n  dataSize: JSON.stringify($input.all()).length,\n  processingRate: $input.all().length / Math.max(1, (Date.now() - (inputData.workflowStatus?.startTime || Date.now())) / 1000)\n};\n\n// è®°å½•æ—¥å¿—\nconst logEntry = log(logLevelOverride, logCategory, logMessage, {\n  ...logMetadata,\n  performanceMetrics,\n  inputDataSummary: {\n    itemCount: $input.all().length,\n    hasErrors: inputData.errors && inputData.errors.length > 0,\n    status: inputData.status || 'unknown',\n    phase: inputData.workflowStatus?.phase || 'unknown'\n  }\n});\n\n// è¿”å›åŸå§‹æ•°æ®å’Œæ—¥å¿—ä¿¡æ¯\nreturn {\n  json: {\n    ...inputData,\n    logEntry: logEntry,\n    logged: true,\n    logTimestamp: new Date().toISOString()\n  }\n};"
      },
      "id": "workflow-logger",
      "name": "ç»Ÿä¸€æ—¥å¿—è®°å½•å™¨",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [680, 300],
      "continueOnFail": true
    },
    
    {
      "parameters": {
        "functionCode": "// RSSé‡‡é›†é€»è¾‘ - å¢å¼ºç‰ˆ (å«ç›‘æ§)\nconst axios = require('axios');\nconst xml2js = require('xml2js');\n\nconst inputData = $input.first().json;\nconst rssSources = inputData.rssSources;\nconst workflowStatus = inputData.workflowStatus;\nconst metricsCollector = workflowStatus.metricsCollector;\n\nconst collectedItems = [];\nconst errors = [];\nconst sourceStats = [];\nconst apiCalls = [];\n\n// æ›´æ–°å·¥ä½œæµçŠ¶æ€\nworkflowStatus.phase = 'rss_collection';\nworkflowStatus.currentStep = 3;\n\n// RSSé‡‡é›†å‡½æ•° - å¢å¼ºç›‘æ§\nasync function fetchRSSFeed(source) {\n  const startTime = Date.now();\n  const apiCall = {\n    endpoint: source.url,\n    method: 'GET',\n    startTime: startTime\n  };\n  \n  try {\n    console.log(`ğŸ“¡ å¼€å§‹é‡‡é›†RSSæº: ${source.name}`);\n    \n    const response = await axios.get(source.url, {\n      timeout: 30000,\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (compatible; n8n-news-collector/1.0)',\n        'Accept': 'application/rss+xml, application/xml, text/xml'\n      }\n    });\n\n    const parser = new xml2js.Parser({\n      explicitArray: false,\n      ignoreAttrs: false,\n      mergeAttrs: true\n    });\n\n    const result = await parser.parseStringPromise(response.data);\n    const items = result.rss?.channel?.item || result.feed?.entry || [];\n    \n    let processedItems = Array.isArray(items) ? items : [items].filter(Boolean);\n    processedItems = processedItems.slice(0, 10);\n    \n    const processingTime = Date.now() - startTime;\n    \n    // è®°å½•APIè°ƒç”¨æˆåŠŸ\n    apiCall.responseTime = processingTime;\n    apiCall.success = true;\n    apiCall.statusCode = response.status;\n    apiCalls.push(apiCall);\n    \n    sourceStats.push({\n      source: source.name,\n      status: 'success',\n      itemCount: processedItems.length,\n      processingTime: processingTime,\n      url: source.url,\n      responseSize: JSON.stringify(response.data).length\n    });\n    \n    console.log(`âœ… RSSé‡‡é›†æˆåŠŸ - ${source.name}: ${processedItems.length}æ¡ (${processingTime}ms)`);\n    return processedItems;\n    \n  } catch (error) {\n    const processingTime = Date.now() - startTime;\n    \n    // è®°å½•APIè°ƒç”¨å¤±è´¥\n    apiCall.responseTime = processingTime;\n    apiCall.success = false;\n    apiCall.error = error.message;\n    apiCall.statusCode = error.response?.status || 0;\n    apiCalls.push(apiCall);\n    \n    console.error(`âŒ RSSé‡‡é›†å¤±è´¥ - ${source.name}:`, error.message);\n    \n    errors.push({\n      source: source.name,\n      error: error.message,\n      type: 'rss',\n      url: source.url,\n      timestamp: new Date().toISOString(),\n      severity: 'medium',\n      retryable: true\n    });\n    \n    sourceStats.push({\n      source: source.name,\n      status: 'failed',\n      itemCount: 0,\n      processingTime: processingTime,\n      error: error.message,\n      url: source.url\n    });\n    \n    return [];\n  }\n}\n\n// æ•°æ®æ ‡å‡†åŒ–å‡½æ•° - ä¿æŒåŸæœ‰é€»è¾‘\nfunction normalizeRSSItem(item, source) {\n  const publishDate = item.pubDate || item.published || item.updated || new Date().toISOString();\n  \n  let content = '';\n  if (item.content) {\n    content = typeof item.content === 'object' ? (item.content._ || item.content) : item.content;\n  } else if (item.description) {\n    content = typeof item.description === 'object' ? (item.description._ || item.description) : item.description;\n  } else if (item.summary) {\n    content = typeof item.summary === 'object' ? (item.summary._ || item.summary) : item.summary;\n  }\n  \n  content = content.replace(/<[^>]*>/g, '').trim();\n  \n  let title = '';\n  if (item.title) {\n    title = typeof item.title === 'object' ? (item.title._ || item.title) : item.title;\n  }\n  title = title.replace(/<[^>]*>/g, '').trim();\n  \n  return {\n    title: title || 'æ— æ ‡é¢˜',\n    content: content || 'æ— å†…å®¹',\n    summary: content.substring(0, 200) + (content.length > 200 ? '...' : ''),\n    author: item.author?.name || item.author || item['dc:creator'] || source.name,\n    source: source.name,\n    category: source.category,\n    categoryId: source.categoryId,\n    source_url: item.link?.href || item.link || item.guid?._ || item.guid || '',\n    image_url: item.enclosure?.url || item['media:thumbnail']?.url || item['media:content']?.url || '',\n    keywords: Array.isArray(item.category) ? item.category.join(',') : (item.category || ''),\n    publishedAt: publishDate,\n    collectedAt: new Date().toISOString(),\n    sourceType: 'rss',\n    \n    dataQuality: {\n      hasTitle: !!title,\n      hasContent: !!content,\n      hasImage: !!(item.enclosure?.url || item['media:thumbnail']?.url),\n      hasAuthor: !!(item.author?.name || item.author || item['dc:creator']),\n      contentLength: content.length,\n      titleLength: title.length\n    },\n    \n    processingMetadata: {\n      collectionTime: Date.now(),\n      sourceUrl: source.url,\n      parsingMethod: 'xml2js'\n    },\n    \n    originalData: item\n  };\n}\n\n// å¹¶è¡Œé‡‡é›†æ‰€æœ‰RSSæº\nconst rssPromises = rssSources.map(async (source) => {\n  const items = await fetchRSSFeed(source);\n  return items.map(item => normalizeRSSItem(item, source));\n});\n\ntry {\n  const rssResults = await Promise.all(rssPromises);\n  \n  rssResults.forEach(sourceItems => {\n    collectedItems.push(...sourceItems);\n  });\n  \n  // æ”¶é›†æ€§èƒ½æŒ‡æ ‡\n  if (metricsCollector) {\n    const workflowMetrics = metricsCollector.collectWorkflowMetrics({\n      executionId: workflowStatus.executionId,\n      workflowId: workflowStatus.workflowId,\n      workflowName: workflowStatus.workflowName,\n      nodeId: $node.id,\n      nodeName: $node.name,\n      itemsProcessed: collectedItems.length,\n      dataSize: JSON.stringify(collectedItems).length,\n      successCount: collectedItems.length,\n      errorCount: errors.length\n    });\n    \n    const apiMetrics = metricsCollector.collectApiMetrics(apiCalls);\n    \n    // æ£€æŸ¥æ€§èƒ½é˜ˆå€¼\n    const performanceAlerts = metricsCollector.checkPerformanceThresholds({\n      workflow: workflowMetrics,\n      api: apiMetrics\n    });\n    \n    workflowStatus.performanceMetrics = {\n      workflow: workflowMetrics,\n      api: apiMetrics\n    };\n    \n    workflowStatus.performanceAlerts = performanceAlerts;\n  }\n  \n  // æ•°æ®è´¨é‡ç»Ÿè®¡\n  const qualityStats = {\n    totalItems: collectedItems.length,\n    itemsWithImages: collectedItems.filter(item => item.image_url).length,\n    itemsWithAuthors: collectedItems.filter(item => item.author !== item.source).length,\n    averageContentLength: collectedItems.reduce((sum, item) => sum + item.content.length, 0) / collectedItems.length || 0,\n    averageTitleLength: collectedItems.reduce((sum, item) => sum + item.title.length, 0) / collectedItems.length || 0\n  };\n  \n  // æ›´æ–°å·¥ä½œæµçŠ¶æ€\n  workflowStatus.rssCollection = {\n    completed: true,\n    itemsCollected: collectedItems.length,\n    sourcesProcessed: rssSources.length,\n    successfulSources: sourceStats.filter(s => s.status === 'success').length,\n    failedSources: sourceStats.filter(s => s.status === 'failed').length,\n    totalProcessingTime: Date.now() - workflowStatus.startTime,\n    qualityStats: qualityStats,\n    apiCallsCount: apiCalls.length,\n    averageResponseTime: apiCalls.reduce((sum, call) => sum + call.responseTime, 0) / apiCalls.length || 0\n  };\n  \n  console.log(`ğŸ“Š RSSé‡‡é›†å®Œæˆç»Ÿè®¡:`, JSON.stringify({\n    æ€»æ¡æ•°: collectedItems.length,\n    é”™è¯¯æ•°: errors.length,\n    æˆåŠŸæº: workflowStatus.rssCollection.successfulSources,\n    å¤±è´¥æº: workflowStatus.rssCollection.failedSources,\n    å¹³å‡å†…å®¹é•¿åº¦: Math.round(qualityStats.averageContentLength),\n    å¸¦å›¾ç‰‡æ¯”ä¾‹: Math.round((qualityStats.itemsWithImages / collectedItems.length) * 100) + '%',\n    å¹³å‡å“åº”æ—¶é—´: Math.round(workflowStatus.rssCollection.averageResponseTime) + 'ms'\n  }));\n  \n  return {\n    json: {\n      items: collectedItems,\n      errors,\n      sourceStats,\n      qualityStats,\n      workflowStatus,\n      apiCalls,\n      summary: {\n        totalItems: collectedItems.length,\n        errorCount: errors.length,\n        sources: rssSources.length,\n        collectedAt: new Date().toISOString(),\n        processingTime: Date.now() - workflowStatus.startTime\n      },\n      \n      // æ—¥å¿—è®°å½•å…ƒæ•°æ®\n      logMetadata: {\n        category: 'data_collection',\n        message: `RSSé‡‡é›†å®Œæˆ: ${collectedItems.length}æ¡æ•°æ®`,\n        level: errors.length > 0 ? 'warn' : 'info',\n        phase: 'rss_collection',\n        step: 3,\n        totalSteps: 8\n      }\n    }\n  };\n  \n} catch (error) {\n  console.error('âŒ RSSæ‰¹é‡é‡‡é›†å¤±è´¥:', error);\n  \n  workflowStatus.rssCollection = {\n    completed: false,\n    error: error.message,\n    failedAt: new Date().toISOString()\n  };\n  \n  // è®°å½•ä¸¥é‡é”™è¯¯\n  errors.push({\n    source: 'RSSæ‰¹é‡é‡‡é›†',\n    error: error.message,\n    type: 'rss_batch',\n    timestamp: new Date().toISOString(),\n    severity: 'critical',\n    retryable: false\n  });\n  \n  return {\n    json: {\n      status: 'error',\n      error: error.message,\n      errors,\n      workflowStatus,\n      \n      // é”™è¯¯æ—¥å¿—å…ƒæ•°æ®\n      logMetadata: {\n        category: 'error',\n        message: `RSSé‡‡é›†å¤±è´¥: ${error.message}`,\n        level: 'error',\n        phase: 'rss_collection',\n        step: 3,\n        totalSteps: 8\n      }\n    }\n  };\n}"
      },
      "id": "enhanced-rss-collector",
      "name": "å¢å¼ºRSSé‡‡é›†å™¨(å«ç›‘æ§)",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [900, 200]
    },
    
    {
      "parameters": {
        "functionCode": "// æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†å™¨\nconst inputData = $input.first()?.json || {};\nconst workflowStatus = inputData.workflowStatus || {};\nconst metricsCollector = workflowStatus.metricsCollector;\n\nif (!metricsCollector) {\n  console.warn('âš ï¸ æ€§èƒ½ç›‘æ§å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ€§èƒ½åˆ†æ');\n  return {\n    json: {\n      ...inputData,\n      performanceMonitored: false,\n      monitoringSkipped: true\n    }\n  };\n}\n\nconst startTime = Date.now();\n\n// æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡\nconst systemMetrics = metricsCollector.collectSystemMetrics();\n\n// æ”¶é›†å·¥ä½œæµæ€§èƒ½æŒ‡æ ‡\nconst workflowMetrics = metricsCollector.collectWorkflowMetrics({\n  executionId: workflowStatus.executionId,\n  workflowId: workflowStatus.workflowId,\n  workflowName: workflowStatus.workflowName,\n  nodeId: $node.id,\n  nodeName: $node.name,\n  itemsProcessed: inputData.items?.length || 0,\n  dataSize: JSON.stringify(inputData.items || []).length,\n  successCount: inputData.items?.length || 0,\n  errorCount: inputData.errors?.length || 0,\n  averageQualityScore: inputData.qualityStats?.averageQualityScore || 0\n});\n\n// æ”¶é›†APIæ€§èƒ½æŒ‡æ ‡\nconst apiMetrics = metricsCollector.collectApiMetrics(inputData.apiCalls || []);\n\n// æ”¶é›†è‡ªå®šä¹‰æŒ‡æ ‡\nconst customMetrics = metricsCollector.collectCustomMetrics({\n  sourceDistribution: inputData.sourceStats?.reduce((acc, stat) => {\n    acc[stat.source] = stat.itemCount;\n    return acc;\n  }, {}) || {},\n  qualityScoreDistribution: inputData.qualityStats || {},\n  contentPublishRate: inputData.items?.length || 0\n});\n\n// åˆå¹¶æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡\nconst allMetrics = {\n  system: systemMetrics,\n  workflow: workflowMetrics,\n  api: apiMetrics,\n  custom: customMetrics,\n  collection: {\n    timestamp: Date.now(),\n    collectionTime: Date.now() - startTime,\n    nodeId: $node.id,\n    nodeName: $node.name\n  }\n};\n\n// æ£€æŸ¥æ€§èƒ½é˜ˆå€¼å¹¶ç”Ÿæˆå‘Šè­¦\nconst performanceAlerts = metricsCollector.checkPerformanceThresholds(allMetrics);\n\n// åˆ†ææ€§èƒ½è¶‹åŠ¿\nconst performanceTrends = metricsCollector.analyzePerformanceTrends('1h');\n\n// ç”Ÿæˆæ€§èƒ½æ‘˜è¦\nconst performanceSummary = {\n  status: performanceAlerts.some(alert => alert.type === 'critical') ? 'critical' : \n          performanceAlerts.some(alert => alert.type === 'warning') ? 'warning' : 'healthy',\n  executionTime: workflowMetrics.execution?.totalExecutionTime || 0,\n  memoryUsage: systemMetrics.memory?.heapUsagePercent || 0,\n  throughput: workflowMetrics.execution?.throughput || 0,\n  errorRate: workflowMetrics.quality?.errorRate || 0,\n  alertCount: performanceAlerts.length,\n  apiResponseTime: apiMetrics.overall?.averageResponseTime || 0\n};\n\n// è®°å½•æ€§èƒ½ç›‘æ§æ—¥å¿—\nconsole.log('ğŸ“Š æ€§èƒ½ç›‘æ§æŠ¥å‘Š:', JSON.stringify({\n  timestamp: new Date().toISOString(),\n  executionId: workflowStatus.executionId,\n  summary: performanceSummary,\n  alerts: performanceAlerts.length > 0 ? performanceAlerts.slice(0, 3) : undefined,\n  trends: {\n    executionTime: performanceTrends.executionTime?.trend || 'stable',\n    memoryUsage: performanceTrends.memoryUsage?.trend || 'stable',\n    throughput: performanceTrends.throughput?.trend || 'stable'\n  }\n}));\n\n// æ›´æ–°å·¥ä½œæµçŠ¶æ€\nworkflowStatus.performanceMetrics = allMetrics;\nworkflowStatus.performanceAlerts = performanceAlerts;\nworkflowStatus.performanceTrends = performanceTrends;\nworkflowStatus.performanceSummary = performanceSummary;\n\nreturn {\n  json: {\n    ...inputData,\n    performanceMetrics: allMetrics,\n    performanceAlerts: performanceAlerts,\n    performanceTrends: performanceTrends,\n    performanceSummary: performanceSummary,\n    workflowStatus: workflowStatus,\n    performanceMonitored: true,\n    monitoringTimestamp: new Date().toISOString(),\n    \n    // æ—¥å¿—è®°å½•å…ƒæ•°æ®\n    logMetadata: {\n      category: 'performance',\n      message: `æ€§èƒ½ç›‘æ§å®Œæˆ - çŠ¶æ€: ${performanceSummary.status}`,\n      level: performanceSummary.status === 'critical' ? 'error' : \n             performanceSummary.status === 'warning' ? 'warn' : 'info',\n      phase: workflowStatus.phase,\n      performanceData: {\n        executionTime: performanceSummary.executionTime,\n        memoryUsage: performanceSummary.memoryUsage,\n        alertCount: performanceSummary.alertCount\n      }\n    }\n  }\n};"
      },
      "id": "performance-monitor",
      "name": "æ€§èƒ½ç›‘æ§å™¨",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1120, 300],
      "continueOnFail": true
    },
    
    {
      "parameters": {
        "functionCode": "// é”™è¯¯å¤„ç†å’Œå‘Šè­¦ç³»ç»Ÿ\nconst inputData = $input.first()?.json || {};\nconst errors = inputData.errors || [];\nconst performanceAlerts = inputData.performanceAlerts || [];\nconst workflowStatus = inputData.workflowStatus || {};\n\nconst enableAlerts = process.env.ENABLE_ERROR_ALERTS !== 'false';\nconst webhookUrl = process.env.WEBHOOK_ALERT_URL;\n\n// é”™è¯¯åˆ†ç±»å‡½æ•°\nfunction classifyError(error) {\n  if (!error) return { category: 'unknown', severity: 'low' };\n  \n  const errorMessage = error.error || error.message || '';\n  \n  if (errorMessage.includes('timeout') || errorMessage.includes('ECONNRESET') || \n      errorMessage.includes('ENOTFOUND') || errorMessage.includes('network')) {\n    return {\n      category: 'network',\n      severity: 'medium',\n      retryable: true,\n      description: 'ç½‘ç»œè¿æ¥é”™è¯¯'\n    };\n  }\n  \n  if (errorMessage.includes('401') || errorMessage.includes('403') || \n      errorMessage.includes('unauthorized') || errorMessage.includes('authentication')) {\n    return {\n      category: 'authentication',\n      severity: 'high',\n      retryable: false,\n      description: 'APIè®¤è¯å¤±è´¥'\n    };\n  }\n  \n  if (errorMessage.includes('429') || errorMessage.includes('rate limit')) {\n    return {\n      category: 'rate_limit',\n      severity: 'medium',\n      retryable: true,\n      description: 'APIè¯·æ±‚é¢‘ç‡é™åˆ¶'\n    };\n  }\n  \n  return {\n    category: error.type || 'unknown',\n    severity: error.severity || 'medium',\n    retryable: error.retryable !== false,\n    description: error.description || 'æœªçŸ¥é”™è¯¯ç±»å‹'\n  };\n}\n\n// ç”Ÿæˆé”™è¯¯æŠ¥å‘Š\nfunction generateErrorReport(error, classification) {\n  return {\n    errorId: `err_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n    timestamp: new Date().toISOString(),\n    executionId: workflowStatus.executionId,\n    workflowId: workflowStatus.workflowId,\n    workflowName: workflowStatus.workflowName,\n    nodeId: $node.id || 'error-handler',\n    nodeName: $node.name || 'é”™è¯¯å¤„ç†å™¨',\n    \n    error: {\n      message: error.error || error.message || 'Unknown error',\n      source: error.source || 'unknown',\n      type: error.type || 'unknown',\n      timestamp: error.timestamp\n    },\n    \n    classification: classification,\n    \n    context: {\n      phase: workflowStatus.phase,\n      step: workflowStatus.currentStep,\n      totalSteps: workflowStatus.totalSteps,\n      itemsProcessed: inputData.items?.length || 0,\n      hasPerformanceIssues: performanceAlerts.length > 0\n    },\n    \n    troubleshooting: generateTroubleshootingTips(classification)\n  };\n}\n\n// ç”Ÿæˆæ•…éšœæ’é™¤å»ºè®®\nfunction generateTroubleshootingTips(classification) {\n  const tips = {\n    network: [\n      'æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸',\n      'éªŒè¯ç›®æ ‡æœåŠ¡æ˜¯å¦å¯è®¿é—®',\n      'è€ƒè™‘å¢åŠ è¶…æ—¶æ—¶é—´',\n      'æ£€æŸ¥é˜²ç«å¢™è®¾ç½®'\n    ],\n    authentication: [\n      'éªŒè¯APIå¯†é’¥æ˜¯å¦æ­£ç¡®',\n      'æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è¿‡æœŸ',\n      'ç¡®è®¤APIæƒé™è®¾ç½®',\n      'æ£€æŸ¥è®¤è¯å¤´æ ¼å¼'\n    ],\n    rate_limit: [\n      'å‡å°‘APIè°ƒç”¨é¢‘ç‡',\n      'å®æ–½æŒ‡æ•°é€€é¿é‡è¯•',\n      'è€ƒè™‘å‡çº§APIå¥—é¤',\n      'åˆ†æ‰¹å¤„ç†æ•°æ®'\n    ]\n  };\n  \n  return tips[classification.category] || [\n    'æ£€æŸ¥é”™è¯¯æ—¥å¿—è¯¦æƒ…',\n    'éªŒè¯è¾“å…¥æ•°æ®',\n    'è”ç³»æŠ€æœ¯æ”¯æŒ',\n    'æŸ¥çœ‹ç›¸å…³æ–‡æ¡£'\n  ];\n}\n\n// å‘é€å‘Šè­¦é€šçŸ¥\nasync function sendAlert(errorReport) {\n  if (!enableAlerts || !webhookUrl) {\n    console.log('âš ï¸ å‘Šè­¦åŠŸèƒ½æœªå¯ç”¨æˆ–æœªé…ç½®Webhook URL');\n    return false;\n  }\n  \n  try {\n    const alertPayload = {\n      type: 'error_alert',\n      severity: errorReport.classification.severity,\n      title: `å·¥ä½œæµé”™è¯¯: ${errorReport.error.message}`,\n      description: errorReport.classification.description,\n      details: {\n        workflowName: errorReport.workflowName,\n        nodeName: errorReport.nodeName,\n        errorCategory: errorReport.classification.category,\n        timestamp: errorReport.timestamp,\n        executionId: errorReport.executionId,\n        phase: errorReport.context.phase\n      },\n      troubleshooting: errorReport.troubleshooting,\n      metadata: {\n        retryable: errorReport.classification.retryable,\n        errorId: errorReport.errorId\n      }\n    };\n    \n    // è¿™é‡Œåº”è¯¥å®é™…å‘é€åˆ°webhookï¼Œä½†åœ¨n8nå‡½æ•°èŠ‚ç‚¹ä¸­æˆ‘ä»¬åªèƒ½æ¨¡æ‹Ÿ\n    console.log('ğŸ“§ å‘Šè­¦é€šçŸ¥ (æ¨¡æ‹Ÿå‘é€):', JSON.stringify(alertPayload));\n    return true;\n    \n  } catch (alertError) {\n    console.error('âŒ å‘é€å‘Šè­¦æ—¶å‡ºé”™:', alertError.message);\n    return false;\n  }\n}\n\n// å¤„ç†é”™è¯¯å’Œå‘Šè­¦\nconst processedErrors = [];\nconst alertsSent = [];\n\n// å¤„ç†å·¥ä½œæµé”™è¯¯\nfor (const error of errors) {\n  const classification = classifyError(error);\n  const errorReport = generateErrorReport(error, classification);\n  \n  processedErrors.push(errorReport);\n  \n  // è®°å½•é”™è¯¯æ—¥å¿—\n  console.error('ğŸš¨ å·¥ä½œæµé”™è¯¯æŠ¥å‘Š:', JSON.stringify({\n    errorId: errorReport.errorId,\n    category: classification.category,\n    severity: classification.severity,\n    message: errorReport.error.message,\n    retryable: classification.retryable,\n    phase: errorReport.context.phase\n  }));\n  \n  // å‘é€é«˜ä¸¥é‡æ€§é”™è¯¯çš„å‘Šè­¦\n  if (classification.severity === 'high' || classification.severity === 'critical') {\n    const alertSent = await sendAlert(errorReport);\n    if (alertSent) {\n      alertsSent.push(errorReport.errorId);\n    }\n  }\n}\n\n// å¤„ç†æ€§èƒ½å‘Šè­¦\nfor (const alert of performanceAlerts) {\n  console.warn('âš ï¸ æ€§èƒ½å‘Šè­¦:', JSON.stringify({\n    metric: alert.metric,\n    value: alert.value,\n    threshold: alert.threshold,\n    message: alert.message,\n    severity: alert.type\n  }));\n  \n  if (alert.type === 'critical') {\n    const alertSent = await sendAlert({\n      type: 'performance_alert',\n      severity: 'critical',\n      title: `æ€§èƒ½å‘Šè­¦: ${alert.message}`,\n      details: {\n        metric: alert.metric,\n        value: alert.value,\n        threshold: alert.threshold,\n        executionId: workflowStatus.executionId\n      }\n    });\n    \n    if (alertSent) {\n      alertsSent.push(`perf_${alert.metric}_${Date.now()}`);\n    }\n  }\n}\n\n// ç”Ÿæˆé”™è¯¯å¤„ç†æ‘˜è¦\nconst errorHandlingSummary = {\n  totalErrors: errors.length,\n  processedErrors: processedErrors.length,\n  criticalErrors: processedErrors.filter(e => e.classification.severity === 'critical').length,\n  retryableErrors: processedErrors.filter(e => e.classification.retryable).length,\n  performanceAlerts: performanceAlerts.length,\n  alertsSent: alertsSent.length,\n  status: processedErrors.some(e => e.classification.severity === 'critical') ? 'critical' :\n          processedErrors.some(e => e.classification.severity === 'high') ? 'warning' : 'stable'\n};\n\nconsole.log('ğŸ” é”™è¯¯å¤„ç†æ‘˜è¦:', JSON.stringify(errorHandlingSummary));\n\nreturn {\n  json: {\n    ...inputData,\n    processedErrors: processedErrors,\n    errorHandlingSummary: errorHandlingSummary,\n    alertsSent: alertsSent,\n    errorHandlingCompleted: true,\n    \n    // æ—¥å¿—è®°å½•å…ƒæ•°æ®\n    logMetadata: {\n      category: 'error_handling',\n      message: `é”™è¯¯å¤„ç†å®Œæˆ - çŠ¶æ€: ${errorHandlingSummary.status}`,\n      level: errorHandlingSummary.status === 'critical' ? 'error' : \n             errorHandlingSummary.status === 'warning' ? 'warn' : 'info',\n      errorData: errorHandlingSummary\n    }\n  }\n};"
      },
      "id": "error-handler",
      "name": "é”™è¯¯å¤„ç†å’Œå‘Šè­¦",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1340, 300],
      "continueOnFail": true
    },
    
    {
      "parameters": {
        "functionCode": "// å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆå™¨\nconst WorkflowExecutionReporter = require('./workflow-execution-reporter.js');\n\nconst inputData = $input.first()?.json || {};\nconst workflowStatus = inputData.workflowStatus || {};\nconst executionReporter = workflowStatus.executionReporter;\n\nif (!executionReporter) {\n  console.warn('âš ï¸ æ‰§è¡ŒæŠ¥å‘Šå™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ');\n  return {\n    json: {\n      ...inputData,\n      reportGenerated: false,\n      reportSkipped: true\n    }\n  };\n}\n\n// æ›´æ–°å·¥ä½œæµçŠ¶æ€ä¸ºå®Œæˆ\nworkflowStatus.phase = 'completion';\nworkflowStatus.currentStep = 8;\nworkflowStatus.endTime = Date.now();\nworkflowStatus.duration = workflowStatus.endTime - workflowStatus.startTime;\nworkflowStatus.status = inputData.errorHandlingSummary?.status === 'critical' ? 'failed' : 'completed';\n\n// å‡†å¤‡æ‰§è¡Œæ•°æ®\nconst executionData = {\n  executionId: workflowStatus.executionId,\n  workflowId: workflowStatus.workflowId,\n  workflowName: workflowStatus.workflowName,\n  startTime: workflowStatus.startTime,\n  endTime: workflowStatus.endTime,\n  duration: workflowStatus.duration,\n  status: workflowStatus.status,\n  \n  // æ­¥éª¤ç»Ÿè®¡\n  totalSteps: workflowStatus.totalSteps,\n  completedSteps: workflowStatus.currentStep,\n  failedSteps: inputData.processedErrors?.filter(e => e.classification.severity === 'critical').length || 0,\n  \n  // æ•°æ®å¤„ç†ç»Ÿè®¡\n  totalItemsCollected: inputData.items?.length || 0,\n  totalItemsProcessed: inputData.items?.length || 0,\n  successfulItems: inputData.items?.length || 0,\n  failedItems: inputData.errors?.length || 0,\n  duplicateItems: inputData.duplicatesFound || 0,\n  publishedItems: inputData.publishedItems || 0,\n  \n  // æ¥æºç»Ÿè®¡\n  sourceStats: inputData.sourceStats || [],\n  qualityStats: inputData.qualityStats || {},\n  \n  // æ€§èƒ½æ•°æ®\n  performanceMetrics: inputData.performanceMetrics || {},\n  performanceAlerts: inputData.performanceAlerts || [],\n  \n  // é”™è¯¯æ•°æ®\n  errors: inputData.errors || [],\n  processedErrors: inputData.processedErrors || [],\n  \n  // å·¥ä½œæµçŠ¶æ€\n  workflowStatus: workflowStatus,\n  \n  // APIè°ƒç”¨ç»Ÿè®¡\n  apiCalls: inputData.apiCalls || []\n};\n\ntry {\n  // ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š\n  const executionReport = await executionReporter.generateExecutionReport(executionData);\n  \n  // ç”ŸæˆæŠ¥å‘Šæ‘˜è¦\n  const reportSummary = {\n    reportId: executionReport.reportMetadata.reportId,\n    executionId: executionData.executionId,\n    status: executionData.status,\n    duration: executionReport.executionSummary.basicInfo.durationFormatted,\n    itemsProcessed: executionData.totalItemsProcessed,\n    successRate: executionReport.executionSummary.itemProcessing.processingSuccessRate,\n    errorCount: executionData.errors.length,\n    performanceScore: executionReport.performanceAnalysis?.performanceScore || 0,\n    generatedAt: executionReport.reportMetadata.generatedAt\n  };\n  \n  console.log('ğŸ“Š å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Šå·²ç”Ÿæˆ:', JSON.stringify(reportSummary));\n  \n  // å¦‚æœæ˜¯å®šæœŸæŠ¥å‘Šæ—¶é—´ï¼Œä¹Ÿç”Ÿæˆå®šæœŸæŠ¥å‘Š\n  const now = new Date();\n  const shouldGeneratePeriodicReport = now.getMinutes() === 0 && now.getHours() % 6 === 0; // æ¯6å°æ—¶\n  \n  let periodicReport = null;\n  if (shouldGeneratePeriodicReport) {\n    try {\n      const endDate = new Date();\n      const startDate = new Date(endDate.getTime() - 6 * 60 * 60 * 1000); // è¿‡å»6å°æ—¶\n      periodicReport = await executionReporter.generatePeriodicReport('6hourly', startDate, endDate);\n      console.log('ğŸ“ˆ å®šæœŸæŠ¥å‘Šå·²ç”Ÿæˆ:', periodicReport.reportMetadata.reportId);\n    } catch (periodicError) {\n      console.error('âŒ ç”Ÿæˆå®šæœŸæŠ¥å‘Šå¤±è´¥:', periodicError.message);\n    }\n  }\n  \n  return {\n    json: {\n      ...inputData,\n      executionReport: executionReport,\n      reportSummary: reportSummary,\n      periodicReport: periodicReport,\n      reportGenerated: true,\n      workflowCompleted: true,\n      finalStatus: executionData.status,\n      \n      // æœ€ç»ˆæ—¥å¿—è®°å½•å…ƒæ•°æ®\n      logMetadata: {\n        category: 'completion',\n        message: `å·¥ä½œæµæ‰§è¡Œå®Œæˆ - çŠ¶æ€: ${executionData.status}`,\n        level: executionData.status === 'failed' ? 'error' : 'info',\n        phase: 'completion',\n        step: 8,\n        totalSteps: 8,\n        finalSummary: reportSummary\n      }\n    }\n  };\n  \n} catch (error) {\n  console.error('âŒ ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Šå¤±è´¥:', error.message);\n  \n  return {\n    json: {\n      ...inputData,\n      reportGenerated: false,\n      reportError: error.message,\n      workflowCompleted: true,\n      finalStatus: 'completed_with_report_error',\n      \n      // é”™è¯¯æ—¥å¿—è®°å½•å…ƒæ•°æ®\n      logMetadata: {\n        category: 'error',\n        message: `æŠ¥å‘Šç”Ÿæˆå¤±è´¥: ${error.message}`,\n        level: 'error',\n        phase: 'completion',\n        step: 8,\n        totalSteps: 8\n      }\n    }\n  };\n}"
      },
      "id": "execution-reporter",
      "name": "æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆå™¨",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1560, 300],
      "continueOnFail": true
    }
  ],
  
  "connections": {
    "cron-trigger": {
      "main": [[\n        {\n          "node": "workflow-initialization",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "workflow-initialization": {\n      "main": [[\n        {\n          "node": "workflow-logger",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "workflow-logger": {\n      "main": [[\n        {\n          "node": "enhanced-rss-collector",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "enhanced-rss-collector": {\n      "main": [[\n        {\n          "node": "performance-monitor",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "performance-monitor": {\n      "main": [[\n        {\n          "node": "error-handler",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "error-handler": {\n      "main": [[\n        {\n          "node": "execution-reporter",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    }\n  },\n  \n  "settings": {\n    "timezone": "Asia/Shanghai",\n    "saveManualExecutions": true,\n    "callerPolicy": "workflowsFromSameOwner",\n    "executionTimeout": 600,\n    "maxExecutionTime": "10 minutes"\n  },\n  \n  "staticData": {},\n  \n  "meta": {\n    "templateCredsSetupCompleted": true\n  },\n  \n  "pinData": {},\n  \n  "versionId": "2.0.0"\n}