name: Automated Backup

on:
  schedule:
    # 每天凌晨2点执行完整备份
    - cron: '0 2 * * *'
    # 每6小时执行数据库备份
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      backup_type:
        description: '备份类型'
        required: true
        default: 'full'
        type: choice
        options:
          - full
          - app
          - database
          - redis
          - config
          - logs
      environment:
        description: '环境'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

env:
  BACKUP_RETENTION_DAYS: 30
  MAX_BACKUP_SIZE: 10G
  COMPRESSION_LEVEL: 6

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      matrix:
        backup_type: 
          - ${{ github.event.inputs.backup_type || (github.event.schedule == '0 2 * * *' && 'full' || 'database') }}
    
    steps:
      - name: Checkout代码
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: 设置环境变量
        run: |
          echo "BACKUP_TIMESTAMP=$(date +%Y%m%d-%H%M%S)" >> $GITHUB_ENV
          echo "ENVIRONMENT=${{ github.event.inputs.environment || 'production' }}" >> $GITHUB_ENV
          echo "BACKUP_TYPE=${{ matrix.backup_type }}" >> $GITHUB_ENV
      
      - name: 创建备份目录
        run: |
          mkdir -p backups
          mkdir -p logs
      
      - name: 检查磁盘空间
        run: |
          df -h
          available_space=$(df . | awk 'NR==2 {print $4}')
          required_space=5242880  # 5GB in KB
          
          if [ $available_space -lt $required_space ]; then
            echo "::warning::磁盘空间不足，可用: ${available_space}KB，建议: ${required_space}KB"
          fi
      
      - name: 设置Docker环境
        run: |
          # 加载环境变量
          if [ -f .env ]; then
            export $(cat .env | grep -v '^#' | xargs)
          fi
          
          # 启动必要的服务用于备份
          docker-compose up -d postgres redis
          
          # 等待服务启动
          sleep 30
          
          # 检查服务状态
          docker-compose ps
      
      - name: 执行备份
        run: |
          chmod +x scripts/backup.sh
          
          # 执行备份脚本
          ./scripts/backup.sh ${{ env.BACKUP_TYPE }} ${{ env.ENVIRONMENT }}
        env:
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      
      - name: 验证备份文件
        run: |
          echo "验证备份文件完整性..."
          
          backup_files=$(find backups -name "*backup*" -type f -newer backups/.backup-start 2>/dev/null || find backups -name "*backup*" -type f -mmin -60)
          
          if [ -z "$backup_files" ]; then
            echo "::error::没有找到新的备份文件"
            exit 1
          fi
          
          for file in $backup_files; do
            echo "检查文件: $file"
            
            # 检查文件大小
            if [ ! -s "$file" ]; then
              echo "::error::备份文件为空: $file"
              exit 1
            fi
            
            # 检查压缩文件完整性
            case "$file" in
              *.tar.gz)
                if ! tar -tzf "$file" > /dev/null 2>&1; then
                  echo "::error::tar.gz文件损坏: $file"
                  exit 1
                fi
                ;;
              *.gz)
                if ! gzip -t "$file" 2>/dev/null; then
                  echo "::error::gzip文件损坏: $file"
                  exit 1
                fi
                ;;
            esac
            
            file_size=$(du -h "$file" | cut -f1)
            echo "✓ 备份文件验证通过: $(basename "$file") ($file_size)"
          done
      
      - name: 上传备份到云存储
        if: success()
        run: |
          # 这里可以添加上传到AWS S3、Google Cloud Storage等的逻辑
          echo "备份文件上传功能待实现"
          
          # 示例：上传到AWS S3
          # aws s3 sync backups/ s3://your-backup-bucket/n8n-backups/$(date +%Y/%m/%d)/
          
          # 示例：上传到Google Cloud Storage
          # gsutil -m rsync -r backups/ gs://your-backup-bucket/n8n-backups/$(date +%Y/%m/%d)/
      
      - name: 清理本地备份
        if: always()
        run: |
          echo "清理超过 $BACKUP_RETENTION_DAYS 天的本地备份..."
          
          find backups -name "*backup*" -type f -mtime +$BACKUP_RETENTION_DAYS -delete 2>/dev/null || true
          find backups -name "backup-manifest-*.txt" -type f -mtime +$BACKUP_RETENTION_DAYS -delete 2>/dev/null || true
          
          # 显示剩余备份文件
          echo "剩余备份文件:"
          ls -la backups/ || echo "备份目录为空"
      
      - name: 生成备份报告
        if: always()
        run: |
          report_file="backup-report-${{ env.BACKUP_TIMESTAMP }}.md"
          
          cat > $report_file << EOF
          # N8N 自动化备份报告
          
          ## 备份信息
          - **备份时间**: $(date '+%Y-%m-%d %H:%M:%S')
          - **备份类型**: ${{ env.BACKUP_TYPE }}
          - **环境**: ${{ env.ENVIRONMENT }}
          - **工作流**: ${{ github.workflow }}
          - **运行ID**: ${{ github.run_id }}
          
          ## 备份文件
          EOF
          
          if [ -d backups ]; then
            echo "| 文件名 | 大小 | 修改时间 |" >> $report_file
            echo "|--------|------|----------|" >> $report_file
            
            find backups -name "*backup*" -type f -mmin -60 2>/dev/null | while read file; do
              filename=$(basename "$file")
              size=$(du -h "$file" | cut -f1)
              mtime=$(stat -c%y "$file" 2>/dev/null | cut -d. -f1)
              echo "| $filename | $size | $mtime |" >> $report_file
            done
          fi
          
          cat >> $report_file << EOF
          
          ## 系统信息
          - **磁盘使用**: $(df -h . | awk 'NR==2 {print $3 "/" $2 " (" $5 ")"}')
          - **备份目录大小**: $(du -sh backups 2>/dev/null | cut -f1 || echo "0B")
          
          ## 状态
          - **备份状态**: ${{ job.status }}
          - **完成时间**: $(date '+%Y-%m-%d %H:%M:%S')
          EOF
          
          echo "备份报告已生成: $report_file"
          cat $report_file
      
      - name: 上传备份报告
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backup-report-${{ env.BACKUP_TIMESTAMP }}
          path: backup-report-*.md
          retention-days: 30
      
      - name: 发送通知
        if: always()
        run: |
          status="${{ job.status }}"
          backup_type="${{ env.BACKUP_TYPE }}"
          environment="${{ env.ENVIRONMENT }}"
          
          case "$status" in
            "success")
              color="good"
              message="✅ N8N备份成功完成"
              ;;
            "failure")
              color="danger"
              message="❌ N8N备份执行失败"
              ;;
            *)
              color="warning"
              message="⚠️ N8N备份执行异常"
              ;;
          esac
          
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data "{
                \"attachments\": [{
                  \"color\": \"$color\",
                  \"title\": \"$message\",
                  \"fields\": [
                    {\"title\": \"备份类型\", \"value\": \"$backup_type\", \"short\": true},
                    {\"title\": \"环境\", \"value\": \"$environment\", \"short\": true},
                    {\"title\": \"工作流\", \"value\": \"${{ github.workflow }}\", \"short\": true},
                    {\"title\": \"运行ID\", \"value\": \"${{ github.run_id }}\", \"short\": true},
                    {\"title\": \"提交\", \"value\": \"${{ github.sha }}\", \"short\": true},
                    {\"title\": \"分支\", \"value\": \"${{ github.ref_name }}\", \"short\": true}
                  ],
                  \"footer\": \"GitHub Actions\",
                  \"ts\": $(date +%s)
                }]
              }" \
              "${{ secrets.SLACK_WEBHOOK_URL }}" || echo "Slack通知发送失败"
          fi

  cleanup-old-backups:
    runs-on: ubuntu-latest
    needs: backup
    if: always()
    
    steps:
      - name: Checkout代码
        uses: actions/checkout@v4
      
      - name: 清理旧的工作流运行
        uses: actions/github-script@v7
        with:
          script: |
            const { data: runs } = await github.rest.actions.listWorkflowRuns({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'backup.yml',
              per_page: 100
            });
            
            // 保留最近30次运行，删除更早的
            const runsToDelete = runs.workflow_runs.slice(30);
            
            for (const run of runsToDelete) {
              try {
                await github.rest.actions.deleteWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: run.id
                });
                console.log(`已删除工作流运行: ${run.id}`);
              } catch (error) {
                console.log(`删除工作流运行失败: ${run.id}, 错误: ${error.message}`);
              }
            }
      
      - name: 清理旧的构件
        uses: actions/github-script@v7
        with:
          script: |
            const { data: artifacts } = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            
            const thirtyDaysAgo = new Date();
            thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
            
            for (const artifact of artifacts.artifacts) {
              const createdAt = new Date(artifact.created_at);
              
              if (createdAt < thirtyDaysAgo) {
                try {
                  await github.rest.actions.deleteArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: artifact.id
                  });
                  console.log(`已删除构件: ${artifact.name}`);
                } catch (error) {
                  console.log(`删除构件失败: ${artifact.name}, 错误: ${error.message}`);
                }
              }
            }